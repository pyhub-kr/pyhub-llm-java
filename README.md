# PyHub LLM Java

[![Maven Central](https://img.shields.io/maven-central/v/kr.pyhub/pyhub-llm)](https://central.sonatype.com/artifact/kr.pyhub/pyhub-llm)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Java](https://img.shields.io/badge/Java-8%2B-orange)](https://www.oracle.com/java/)
[![Build Status](https://github.com/pyhub-kr/pyhub-llm-java/workflows/CI/badge.svg)](https://github.com/pyhub-kr/pyhub-llm-java/actions)

PyHub LLM JavaëŠ” ì—¬ëŸ¬ LLM í”„ë¡œë°”ì´ë”(OpenAI, Anthropic, Upstage ë“±)ì— ëŒ€í•œ í†µí•© ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” Java ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. 
Pythonì˜ [pyhub-llm](https://github.com/pyhub-kr/pyhub-llm) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ Javaë¡œ í¬íŒ…í•˜ì˜€ìŠµë‹ˆë‹¤.

## âœ¨ ì£¼ìš” íŠ¹ì§•

- **ğŸ”— í†µí•© ì¸í„°í˜ì´ìŠ¤**: ëª¨ë“  LLM í”„ë¡œë°”ì´ë”ë¥¼ ë™ì¼í•œ APIë¡œ ì‚¬ìš©
- **âš¡ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›**: `Flux<StreamChunk>`ë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì‘ë‹µ ì²˜ë¦¬
- **ğŸ’¾ ìºì‹± ì‹œìŠ¤í…œ**: ë©”ëª¨ë¦¬ ë° íŒŒì¼ ê¸°ë°˜ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
- **ğŸ› ï¸ ë„êµ¬ í˜¸ì¶œ**: í™•ì¥ ê°€ëŠ¥í•œ í•¨ìˆ˜/ë„êµ¬ í˜¸ì¶œ ê¸°ëŠ¥
- **ğŸ’¬ ëŒ€í™” ê´€ë¦¬**: ìë™ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ ë° ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
- **â˜• Java 8+ í˜¸í™˜**: Java 8 ì´ìƒì—ì„œ ì‹¤í–‰ ê°€ëŠ¥
- **ğŸ“¦ ê³µì‹ SDK ì‚¬ìš©**: OpenAIì™€ Anthropicì˜ ê³µì‹ Java SDK ì‚¬ìš©
- **ğŸ”§ ì„¤ì • ìœ ì—°ì„±**: Builder íŒ¨í„´ê³¼ í™˜ê²½ë³€ìˆ˜ ì§€ì›
- **ğŸ§ª í¬ê´„ì  í…ŒìŠ¤íŠ¸**: 78ê°œ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ë¡œ ê²€ì¦ëœ ì•ˆì •ì„±

## ğŸ“¦ ì„¤ì¹˜

### Maven

```xml
<dependency>
    <groupId>kr.pyhub</groupId>
    <artifactId>pyhub-llm</artifactId>
    <version>0.1.0</version>
</dependency>
```

### Gradle

```gradle
dependencies {
    implementation 'kr.pyhub:pyhub-llm:0.1.0'
}
```

### Gradle (Kotlin DSL)

```kotlin
dependencies {
    implementation("kr.pyhub:pyhub-llm:0.1.0")
}
```

### SBT

```scala
libraryDependencies += "kr.pyhub" % "pyhub-llm" % "0.1.0"
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ê¸°ë³¸ ì‚¬ìš©ë²•

```java
import kr.pyhub.llm.LLM;
import kr.pyhub.llm.types.LLMReply;

// í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
LLM llm = LLM.create("gpt-4o-mini");
LLMReply reply = llm.ask("ì•ˆë…•í•˜ì„¸ìš”!");
System.out.println(reply.getText());
```

### ì„¤ì • ì˜µì…˜ ì‚¬ìš©

```java
import kr.pyhub.llm.Config;

Config config = Config.builder()
    .apiKey("your-api-key")
    .temperature(0.7)
    .maxTokens(1000)
    .build();

LLM llm = LLM.create("gpt-4o-mini", config)
    .withSystemPrompt("You are a helpful assistant");
    
LLMReply reply = llm.ask("Tell me a joke");
System.out.println(reply.getText());
```

### ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

```java
import reactor.core.publisher.Flux;
import kr.pyhub.llm.types.StreamChunk;

LLM llm = LLM.create("gpt-4o-mini");
Flux<StreamChunk> stream = llm.askStream("Write a short story");

stream.subscribe(chunk -> {
    if (chunk.getContent() != null) {
        System.out.print(chunk.getContent());
    }
    if (chunk.isFinished()) {
        System.out.println("\n[ì™„ë£Œ: " + chunk.getFinishReason() + "]");
    }
});
```

### ëŒ€í™” ê´€ë¦¬ (ìë™ íˆìŠ¤í† ë¦¬)

```java
// ëŒ€í™” ëª¨ë“œ í™œì„±í™”
LLM llm = LLM.create("gpt-4o-mini")
    .enableConversation("You are a helpful assistant");

// ìë™ìœ¼ë¡œ ëŒ€í™” ê¸°ë¡ì´ ìœ ì§€ë©ë‹ˆë‹¤
LLMReply reply1 = llm.chat("My name is John");
LLMReply reply2 = llm.chat("What's my name?"); // "John"ì´ë¼ê³  ê¸°ì–µí•¨

// ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
llm.clearConversation();
```

### ìºì‹± ì‚¬ìš©

```java
import kr.pyhub.llm.cache.MemoryCache;

MemoryCache cache = new MemoryCache()
    .withMaxSize(1000)
    .withTtlMinutes(60);

LLM llm = LLM.create("gpt-4o-mini")
    .withCache(cache);

// ë™ì¼í•œ ì§ˆë¬¸ì€ ìºì‹œì—ì„œ ì¦‰ì‹œ ì‘ë‹µ
LLMReply reply1 = llm.ask("What is 2+2?"); // API í˜¸ì¶œ
LLMReply reply2 = llm.ask("What is 2+2?"); // ìºì‹œì—ì„œ ì‘ë‹µ
```

### ë¹„ë™ê¸° í˜¸ì¶œ

```java
import java.util.concurrent.CompletableFuture;

LLM llm = LLM.create("gpt-4o-mini");
CompletableFuture<LLMReply> future = llm.askAsync("What is the meaning of life?");

future.thenAccept(reply -> {
    System.out.println(reply.getText());
});
```

## ğŸ¤– ì§€ì›í•˜ëŠ” ëª¨ë¸

### OpenAI âœ…
- `gpt-4`, `gpt-4-turbo`, `gpt-4o`, `gpt-4o-mini`
- `gpt-3.5-turbo`, `gpt-3.5-turbo-16k`

### Anthropic (Claude) âœ…
- `claude-3-5-sonnet-20240620`
- `claude-3-opus-20240229`, `claude-3-sonnet-20240229`, `claude-3-haiku-20240307`
- `claude-2.1`, `claude-2.0`, `claude-instant-1.2`

### Upstage (Solar) âœ…
- `solar-1-mini-chat` - í•œêµ­ì–´ ìµœì í™” ëª¨ë¸
- `solar-1-mini-chat-ja` - ì¼ë³¸ì–´ ì§€ì› ëª¨ë¸

### Google (Gemini) ğŸš§
- `gemini-pro`, `gemini-pro-vision`
- `gemini-1.5-pro`, `gemini-1.5-flash`

### Ollama (ë¡œì»¬) ğŸš§
- `ollama:llama2`, `ollama:mistral`, `ollama:codellama`

**ë²”ë¡€:**
- âœ… ì™„ì „ êµ¬í˜„ë¨
- ğŸš§ ê°œë°œ ì¤‘ (ê¸°ë³¸ êµ¬ì¡°ë§Œ êµ¬í˜„)

## í™˜ê²½ë³€ìˆ˜

ê° í”„ë¡œë°”ì´ë”ì— í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:

```bash
# OpenAI
export OPENAI_API_KEY="your-openai-api-key"
export OPENAI_ORG_ID="your-org-id"           # ì„ íƒì‚¬í•­
export OPENAI_PROJECT_ID="your-project-id"   # ì„ íƒì‚¬í•­

# Anthropic
export ANTHROPIC_API_KEY="your-anthropic-api-key"

# Google
export GOOGLE_API_KEY="your-google-api-key"

# Upstage
export UPSTAGE_API_KEY="your-upstage-api-key"

# Ollama (ë¡œì»¬ ì„œë²„)
export OLLAMA_HOST="http://localhost:11434"  # ê¸°ë³¸ê°’
```

## ì»¤ìŠ¤í…€ í”„ë¡œë°”ì´ë”

ìƒˆë¡œìš´ í”„ë¡œë°”ì´ë”ë¥¼ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```java
LLM.registerProvider("custom", (model, config) -> {
    return new CustomLLM(model, config);
});

// ì‚¬ìš©
LLM customLlm = LLM.create("custom:my-model");
```

## ê°œë°œ í™˜ê²½ ì„¤ì •

### ìš”êµ¬ì‚¬í•­

- Java 8 ì´ìƒ
- Gradle 7.x

### ë¹Œë“œ

```bash
./gradlew build
```

### í…ŒìŠ¤íŠ¸

```bash
./gradlew test
```

### JAR ìƒì„±

```bash
./gradlew shadowJar
```

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### ë„êµ¬/í•¨ìˆ˜ í˜¸ì¶œ

```java
import kr.pyhub.llm.tools.Tool;
import kr.pyhub.llm.tools.ToolRegistry;

// ì»¤ìŠ¤í…€ ë„êµ¬ ì •ì˜
Tool calculator = Tool.builder()
    .name("calculator")
    .description("ê°„ë‹¨í•œ ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤")
    .parameter("expression", "ê³„ì‚°í•  ìˆ˜ì‹", true)
    .execute(args -> {
        String expr = (String) args.get("expression");
        // ê³„ì‚° ë¡œì§ êµ¬í˜„
        return ToolResult.success("ê²°ê³¼: " + result);
    })
    .build();

LLM llm = LLM.create("gpt-4o-mini")
    .withTools(calculator);
```

### íŒŒì¼ ìºì‹±

```java
import kr.pyhub.llm.cache.FileCache;

FileCache fileCache = new FileCache("./cache")
    .withTtlHours(24);

LLM llm = LLM.create("gpt-4o-mini")
    .withCache(fileCache);
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

- **ë©”ëª¨ë¦¬ ìºì‹±**: Caffeine ê¸°ë°˜ ê³ ì„±ëŠ¥ ìºì‹œ
- **íŒŒì¼ ìºì‹±**: JSON ì§ë ¬í™”ë¥¼ í†µí•œ ì˜êµ¬ ìºì‹œ
- **ì—°ê²° í’€ë§**: OkHttp ì—°ê²° ì¬ì‚¬ìš©
- **ìŠ¤íŠ¸ë¦¬ë°**: ëŒ€ìš©ëŸ‰ ì‘ë‹µì˜ ì‹¤ì‹œê°„ ì²˜ë¦¬
- **ë¹„ë™ê¸° ì²˜ë¦¬**: CompletableFuture ì§€ì›

## ğŸ”— Maven Central

ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” Maven Centralì— ë°°í¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
- **Group ID**: `kr.pyhub`
- **Artifact ID**: `pyhub-llm`
- **Latest Version**: `0.1.0`

## ğŸ“š ì˜ˆì‹œ í”„ë¡œì íŠ¸

- [examples/0001-java-cli-chat](examples/0001-java-cli-chat) - OpenAI ê¸°ë°˜ CLI ì±—ë´‡
- [examples/0002-upstage-cli-chat](examples/0002-upstage-cli-chat) - Upstage Solar ê¸°ë°˜ í•œêµ­ì–´ ì±—ë´‡

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” [Apache 2.0 ë¼ì´ì„ ìŠ¤](LICENSE) í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ê¸°ì—¬ëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤! ë‹¤ìŒ ë°©ë²•ìœ¼ë¡œ ì°¸ì—¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. ğŸ› [ì´ìŠˆ ì‹ ê³ ](https://github.com/pyhub-kr/pyhub-llm-java/issues)
2. ğŸ’¡ [ê¸°ëŠ¥ ì œì•ˆ](https://github.com/pyhub-kr/pyhub-llm-java/issues)
3. ğŸ”§ [Pull Request](https://github.com/pyhub-kr/pyhub-llm-java/pulls)

## ğŸ“ ì§€ì›

- ğŸ“– [ë¬¸ì„œ](https://github.com/pyhub-kr/pyhub-llm-java/wiki)
- ğŸ [ì´ìŠˆ íŠ¸ë˜ì»¤](https://github.com/pyhub-kr/pyhub-llm-java/issues)
- ğŸ’¬ [í† ë¡ ](https://github.com/pyhub-kr/pyhub-llm-java/discussions)

## ğŸ”— ê´€ë ¨ í”„ë¡œì íŠ¸

- [pyhub-llm (Python)](https://github.com/pyhub-kr/pyhub-llm) - ì›ë³¸ Python ë²„ì „
- [PyHub](https://pyhub.kr) - í•œêµ­ì˜ Python ì»¤ë®¤ë‹ˆí‹°

---

<div align="center">
Made with â¤ï¸ by the PyHub Team
</div>